{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import collections\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from pytorch_pretrained_bert.modeling import BertModel\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s', \n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args():\n",
    "    def __init__(self, input_file=None, output_file=None, bert_model=None, do_lower_case=False, layers=\"-1,-2,-3,-4\", max_seq_length=128, batch_size=16, local_rank=-1, no_cuda=False):\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        self.bert_model = bert_model\n",
    "        self.do_lower_case = do_lower_case\n",
    "        self.layers = layers\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "        self.local_rank = local_rank\n",
    "        self.no_cuda = no_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2020 20:52:23 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/cilab/.cache/torch/pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "01/20/2020 20:52:23 - INFO - __main__ -   device: cuda n_gpu: 4 distributed training: False\n"
     ]
    }
   ],
   "source": [
    "from data_load import NerDataset, pad, VOCAB, tokenizer, tag2idx, idx2tag\n",
    "\n",
    "input_file = '/home/cilab/LabMembers/YS/WWW/finetuning/train.txt'\n",
    "output_file = 'inspect_output.jsonl'\n",
    "#bert_model = '/home/cilab/LabMembers/YS/bert_ner/bert_model/scibert_scivocab_uncased'\n",
    "bert_model = '/home/cilab/LabMembers/YS/bert_ner/new_new_new_model_by_kp20/6.pt'\n",
    "layers = '-1,-5'\n",
    "max_seq_length = 256\n",
    "batch_size = 1\n",
    "\n",
    "args = Args(\n",
    "    input_file=input_file, \n",
    "    output_file=output_file,\n",
    "    bert_model=bert_model, \n",
    "    layers=layers, \n",
    "    max_seq_length=max_seq_length,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    n_gpu = torch.cuda.device_count()\n",
    "else:\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    n_gpu = 1\n",
    "    # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "logger.info(\"device: {} n_gpu: {} distributed training: {}\".format(device, n_gpu, bool(args.local_rank != -1)))\n",
    "\n",
    "layer_indexes = [int(x) for x in args.layers.split(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2020 20:52:29 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/cilab/.cache/torch/pytorch_pretrained_bert/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
    "\n",
    "eval_dataset = NerDataset(args.input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, top_rnns=False, vocab_size=None, device='cpu', finetuning=False, bert_type='bert-base-cased'):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_type)\n",
    "\n",
    "        self.top_rnns=top_rnns\n",
    "        if top_rnns:\n",
    "            self.rnn = nn.LSTM(bidirectional=True, num_layers=2, input_size=768, hidden_size=768//2, batch_first=True)\n",
    "        self.fc = nn.Linear(768, vocab_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.finetuning = finetuning\n",
    "\n",
    "    def forward(self, x, y, ):\n",
    "        '''\n",
    "        x: (N, T). int64\n",
    "        y: (N, T). int64\n",
    "        Returns\n",
    "        enc: (N, T, VOCAB)\n",
    "        '''\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "        \n",
    "        if self.training and self.finetuning:\n",
    "            # print(\"->bert.train()\")\n",
    "            self.bert.train()\n",
    "            encoded_layers, _ = self.bert(x)\n",
    "            enc = encoded_layers[-1]\n",
    "        else:\n",
    "            self.bert.eval()\n",
    "            with torch.no_grad():\n",
    "                encoded_layers, _ = self.bert(x)\n",
    "                enc = encoded_layers[-1]\n",
    "\n",
    "        if self.top_rnns:\n",
    "            enc, _ = self.rnn(enc)\n",
    "        logits = self.fc(enc)\n",
    "        y_hat = logits.argmax(-1)\n",
    "        return encoded_layers, logits, y, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2020 04:27:40 - INFO - pytorch_pretrained_bert.modeling -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/cilab/.cache/torch/pytorch_pretrained_bert/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "01/20/2020 04:27:40 - INFO - pytorch_pretrained_bert.modeling -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/cilab/.cache/torch/pytorch_pretrained_bert/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "01/20/2020 04:27:40 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp20 = Net(True, len(VOCAB), device, False).cuda()\n",
    "kp20_checkpoint = torch.load('/home/cilab/LabMembers/YS/bert_ner/new_new_new_model_by_kp20/6.pt')\n",
    "kp20.load_state_dict(kp20_checkpoint['model_state_dict'],strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2020 04:27:53 - INFO - pytorch_pretrained_bert.modeling -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/cilab/.cache/torch/pytorch_pretrained_bert/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "01/20/2020 04:27:53 - INFO - pytorch_pretrained_bert.modeling -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/cilab/.cache/torch/pytorch_pretrained_bert/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "01/20/2020 04:27:53 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretrained_bert = Net(True, len(VOCAB), device, False).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/20/2020 04:27:54 - INFO - pytorch_pretrained_bert.modeling -   loading weights file bert_model/scibert_scivocab_uncased/pytorch_model.bin\n",
      "01/20/2020 04:27:54 - INFO - pytorch_pretrained_bert.modeling -   loading configuration file bert_model/scibert_scivocab_uncased/config.json\n",
      "01/20/2020 04:27:54 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scibert = Net(True, len(VOCAB), device, False, bert_type='bert_model/scibert_scivocab_uncased').cuda()\n",
    "#scibert_checkpoint = torch.load(args.bert_model)\n",
    "#scibert.load_state_dict(kp20_checkpoint['model_state_dict'],strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_layer(model):\n",
    "    embeddings_layer = list(model.modules())[2]\n",
    "    return embeddings_layer.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kp20_path = \"../kp20k/finetuning/train_20.txt\"\n",
    "kp40_path = \"../kp20k/finetuning/train_40.txt\"\n",
    "kp60_path = \"../kp20k/finetuning/train_60.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kp20_dataset = NerDataset(kp20_path)\n",
    "kp40_dataset = NerDataset(kp40_path)\n",
    "kp60_dataset = NerDataset(kp60_path)\n",
    "\n",
    "kp20_dataloader = data.DataLoader(dataset=kp20_dataset,\n",
    "                                 batch_size=args.batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=4,\n",
    "                                 collate_fn=pad)\n",
    "kp40_dataloader = data.DataLoader(dataset=kp40_dataset,\n",
    "                                 batch_size=args.batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=4,\n",
    "                                 collate_fn=pad)\n",
    "kp60_dataloader = data.DataLoader(dataset=kp60_dataset,\n",
    "                                 batch_size=args.batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=4,\n",
    "                                 collate_fn=pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from pytorch_pretrained_bert.modeling import BertEmbeddings\n",
    "\n",
    "for path in [kp20_path, kp40_path, kp60_path]:\n",
    "    with open(path, 'r') as f:\n",
    "        corpus = \"\"\n",
    "        for i, l in enumerate(tqdm(f.read().split('\\n'))):\n",
    "            if i==0:\n",
    "                continue\n",
    "            piece = l.split(' ')[0]\n",
    "            if \"DOCSTART\" in piece:\n",
    "                continue\n",
    "            corpus += piece + '\\n'\n",
    "        with open(\"./kp_vocab/\"+path.split('/')[-1].replace('.txt', '')+\"origin.txt\", 'wt') as f2:\n",
    "            f2.write(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def make_vocab(dataloader, path):\n",
    "    token_counter = set()\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        words, x, is_heads, tags, y, seqlens = batch\n",
    "        for word in words:\n",
    "            for index, (token, l) in enumerate(zip(tokenizer.tokenize(word), y.numpy()[0])):\n",
    "                if token in ['[CLS]', '[SEP]']:\n",
    "                    continue\n",
    "                token_counter.add(token.lower())\n",
    "    special = ['[UNK]', '[CLS]', '[SEP]', '[MASK]']\n",
    "    for token in special:\n",
    "        token_counter.add(token)\n",
    "    with open(path, 'w') as f:\n",
    "        for token in token_counter:\n",
    "            f.write(token+'\\n')\n",
    "for loader, path in [(kp20_dataloader, \"./kp_vocab/kp20_vocab.txt\"), (kp40_dataloader, \"./kp_vocab/kp40_vocab.txt\"), (kp60_dataloader, \"./kp_vocab/kp60_vocab.txt\")]:\n",
    "    make_vocab(loader, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kp20_vocab = './kp_vocab/kp20_vocab.txt'\n",
    "kp40_vocab = './kp_vocab/kp40_vocab.txt'\n",
    "kp60_vocab = './kp_vocab/kp60_vocab.txt'\n",
    "\n",
    "vocab_size = {}\n",
    "\n",
    "with open(kp20_vocab, 'r+') as f:\n",
    "    vocab_size['20'] = len(f.read().split('\\n'))\n",
    "with open(kp40_vocab, 'r+') as f:\n",
    "    vocab_size['40'] = len(f.read().split('\\n'))\n",
    "with open(kp60_vocab, 'r+') as f:\n",
    "    vocab_size['60'] = len(f.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20': 20151, '40': 21195, '60': 21682}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49147"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28996+20151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50191"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28996+21195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50678"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28996+21682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (rnn): LSTM(768, 384, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scibert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (rnn): LSTM(768, 384, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(49147, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (rnn): LSTM(768, 384, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert.modeling import BertEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp20.bert.embeddings.word_embeddings = nn.Embedding(49147, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(49147, 768)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (rnn): LSTM(768, 384, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = data.DataLoader(dataset=eval_dataset,\n",
    "                                 batch_size=args.batch_size,\n",
    "                                 shuffle=False,\n",
    "                                 num_workers=4,\n",
    "                                 collate_fn=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(5)\n",
    "torch.cuda.manual_seed_all(5)\n",
    "\n",
    "def get_sample(model, iterater):\n",
    "    model.eval()\n",
    "    unique_id = 0\n",
    "\n",
    "    break_point = False\n",
    "    \n",
    "    df_id, df_token, df_feat, df_y, df_pred = [], [], [], [], []\n",
    "    for i, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        if i<2:\n",
    "            continue\n",
    "        elif i==3:\n",
    "            break\n",
    "        #input_ids = input_ids.to(device)\n",
    "        #input_mask = input_mask.to(device)\n",
    "        words, x, is_heads, tags, y, seqlens = batch\n",
    "        #print(words)\n",
    "        #print(tags)\n",
    "        #print(y)\n",
    "        #print(y.numpy()[0])\n",
    "        #for w, l in zip(tokenizer.tokenize(words[0]), y.numpy()[0]):\n",
    "        #    print(l, w)\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(x.cuda(), token_type_ids=None)\n",
    "        embeddings = embeddings.squeeze()\n",
    "        #print(all_encoder_layers)\n",
    "        for word in words:\n",
    "            for index, (token, l) in enumerate(zip(tokenizer.tokenize(word), y.numpy()[0])):\n",
    "                if token in ['[CLS]', '[SEP]']:\n",
    "                    continue\n",
    "                df_id.append(unique_id)\n",
    "                df_token.append(token)\n",
    "                df_feat.append(embeddings[index].cpu().detach().numpy())\n",
    "                df_y.append(l)\n",
    "                unique_id += 1\n",
    "        #print(tags)\n",
    "        #print(embeddings.shape)\n",
    "    df_feat = np.array(df_feat)\n",
    "    feat_cols = ['feat'+str(i) for i in range(df_feat.shape[1])]\n",
    "    df = pd.DataFrame(df_feat, columns=feat_cols)\n",
    "    df['id'] = df_id\n",
    "    df['token'] = df_token\n",
    "    df['label'] = df_y\n",
    "    \n",
    "    return df, feat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def compose_2d(df, feat_cols):\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=80, n_iter=300, random_state=1)\n",
    "    #verbose=1, perplexity=40, \n",
    "    tsne_results = tsne.fit_transform(df.loc[:,feat_cols].values)\n",
    "    return tsne_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6981 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 1/6981 [00:01<2:06:15,  1.09s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6981 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 18 nearest neighbors...\n",
      "[t-SNE] Indexed 19 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 19 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 19 / 19\n",
      "[t-SNE] Mean sigma: 6.155820\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 50.031166\n",
      "[t-SNE] KL divergence after 300 iterations: 0.401843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/6981 [00:01<2:03:58,  1.07s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6981 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 18 nearest neighbors...\n",
      "[t-SNE] Indexed 19 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 19 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 19 / 19\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 48.800755\n",
      "[t-SNE] KL divergence after 300 iterations: 0.418239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/6981 [00:00<1:30:29,  1.29it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 18 nearest neighbors...\n",
      "[t-SNE] Indexed 19 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 19 samples in 0.002s...\n",
      "[t-SNE] Computed conditional probabilities for sample 19 / 19\n",
      "[t-SNE] Mean sigma: 12.252189\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 49.995750\n",
      "[t-SNE] KL divergence after 300 iterations: 0.550009\n"
     ]
    }
   ],
   "source": [
    "plot_data = []\n",
    "\n",
    "for model in [pretrained_bert, kp20, scibert]:\n",
    "    emb_layer = get_embeddings_layer(model)\n",
    "    df, cols = get_sample(emb_layer, eval_dataloader)\n",
    "    feat = compose_2d(df, cols)\n",
    "    plot_data.append((df, feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "def get_plot(df, tsne_results, title):\n",
    "    gcm = plt.get_cmap('Greens')\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    #plt.tight_layout(-0.3)\n",
    "    plt.axis('off')\n",
    "    #plt.margins(x=-0.4,y=-0.4)\n",
    "    #plt.tight_layout()\n",
    "    plt.title(title)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    norm = plt.Normalize(tsne_results[:, 1].min(), tsne_results[:, 1].max())\n",
    "    plt.scatter(tsne_results[:, 0], tsne_results[:, 1], marker=None, s=0)\n",
    "    for i, word in enumerate(df['token']):\n",
    "        if norm(tsne_results[i, 1]) < 0.5:\n",
    "            font_size = 13\n",
    "        elif norm(tsne_results[i, 1]) >= 0.5 and norm(tsne_results[i, 1]) < 0.75:\n",
    "            font_size = 16\n",
    "        elif norm(tsne_results[i, 1]) >= 0.75 and norm(tsne_results[i, 1]) < 0.8:\n",
    "            font_size = 18\n",
    "        elif norm(tsne_results[i, 1]) >= 0.8 and norm(tsne_results[i, 1]) < 0.85:\n",
    "            font_size = 21\n",
    "        elif norm(tsne_results[i, 1]) >= 0.8 and norm(tsne_results[i,\n",
    "                                                                   1]) < 0.9:\n",
    "            font_size = 24\n",
    "        else:\n",
    "            font_size = 28\n",
    "        plt.annotate(word, xy=(tsne_results[i, 0], tsne_results[i, 1]), fontsize=font_size, color=gcm(norm(tsne_results[i, 1])+0.22))\n",
    "        #plt.annotate(word, xy=(tsne_results[i, 0], tsne_results[i, 1]), fontsize=round(font_size)%30)\n",
    "    plt.show()\n",
    "    plt.savefig('emb_result/'+'gg'+'.png') \n",
    "\n",
    "title = [\"Pretrained Bert\", \"KP20k using 20%\", \"SciBert\"]\n",
    "for i, (df, feat) in enumerate(plot_data):\n",
    "    get_plot(df, feat.copy(), title[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

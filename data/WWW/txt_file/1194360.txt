evaluating a new approach to strong web cache consistency with snapshots of collected content the problem of web cache consistency continues to be an important one . current web caches use heuristic-based policies for determining the freshness of cached objects , often forcing content providers to unnecessarily mark their content as uncacheable simply to retain control over it . server-driven invalidation has been proposed as a mechanism for providing strong cache consistency for web objects , but it requires servers to maintain per-client state even for infrequently changing objects . we propose an alternative approach to strong cache consistency , called monarch , which does not require servers to maintain per-client state . in this work we focus on a new approach for evaluation of monarch in comparison with current practice and other cache consistency policies . this approach uses snapshots of content collected from real web sites as input to a simulator . results of the evaluation show monarch generates little more request traffic than an optimal cache coherency policy . 
distributed web retrieval in the ocean of web data , web search engines are the primary way to access content . as the data is on the order of petabytes , current search engines are very large centralized systems based on replicated clusters . web data , however , is always evolving . the number of web sites continues to grow rapidly ( over 270 millions at the beginning of 2011 ) and there are currently more than 20 billion indexed pages . on the other hand , internet users are above one billion and hundreds of million of queries are issued each day . in the near future , centralized systems are likely to become less effective against such a data-query load , thus suggesting the need of fully distributed search engines . such engines need to maintain high quality answers , fast response time , high query throughput , high availability and scalability ; in spite of network latency and scattered data . in this tutorial we present the architecture of current search engines and we explore the main challenges behind the design of all the processes of a distributed web retrieval system crawling , indexing , and query processing . 
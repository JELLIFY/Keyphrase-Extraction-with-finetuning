an objective evaluation criterion for clustering we propose and test an objective criterion for evaluation of clustering performance : how well does a clustering algorithm run on unlabeled data aid a classification algorithm ? the accuracy is quantified using the pac-mdl bound ( 3 ) in a semisupervised setting . clustering algorithms which naturally separate the data according to ( hidden ) labels with a small number of clusters perform well . a simple extension of the argument leads to an objective model selection method . experimental results on text analysis datasets demonstrate that this approach empirically results in very competitive bounds on test set performance on natural datasets .
shrinkage estimator generalizations of proximal support vector machines we give a statistical interpretation of proximal support vector machines ( psvm ) proposed at kdd2001 as linear approximaters to ( nonlinear ) support vector machines ( svm ) . we prove that psvm using a linear kernel is identical to ridge regression , a biased-regression method known in the statistical community for more than thirty years . techniques from the statistical literature to estimate the tuning constant that appears in the svm and psvm framework are discussed . better shrinkage strategies that incorporate more than one tuning constant are suggested . for nonlinear kernels , the minimization problem posed in the psvm framework is equivalent to finding the posterior mode of a bayesian model defined through a gaussian process on the predictor space . apart from providing new insights , these interpretations help us attach an estimate of uncertainty to our predictions and enable us to build richer classes of models . in particular , we propose a new algorithm called psvmmix which is a combination of ridge regression and a gaussian process model . extension to the case of continuous response is straightforward and illustrated with example datasets .
learning to rank with multiple objective functions we investigate the problem of learning to rank with document retrieval from the perspective of learning for multiple objective functions . we present solutions to two open problems in learning to rank : first , we show how multiple measures can be combined into a single graded measure that can be learned . this solves the problem of learning from a ` scorecard ' of measures by making such scorecards comparable , and we show results where a standard web relevance measure ( ndcg ) is used for the top-tier measure , and a relevance measure derived from click data is used for the second-tier measure ; the second-tier measure is shown to significantly improve while leaving the top-tier measure largely unchanged . second , we note that the learning-to-rank problem can itself be viewed as changing as the ranking model learns : for example , early in learning , adjusting the rank of all documents can be advantageous , but later during training , it becomes more desirable to concentrate on correcting the top few documents for each query . we show how an analysis of these problems leads to an improved , iteration-dependent cost function that interpolates between a cost function that is more appropriate for early learning , with one that is more appropriate for late-stage learning . the approach results in a significant improvement in accuracy with the same size models . we investigate these ideas using lambdamart , a state-of-the-art ranking algorithm . 
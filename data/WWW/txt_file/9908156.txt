gigahash : scalable minimal perfect hashing for billions of urls a minimal perfect function maps a static set of n keys on to the range of integers { 0,1,2 , ... , n - 1 } . we present a scalable high performance algorithm based on random graphs for constructing minimal perfect hash functions ( mphfs ) . for a set of n keys , our algorithm outputs a description of h in expected time o ( n ) . the evaluation of h ( x ) requires three memory accesses for any key x and the description of h takes up 0.89 n bytes ( 7.13 n bits ) . this is the best ( most space efficient ) known result to date . using a simple heuristic and huffman coding , the space requirement is further reduced to 0.79 n bytes ( 6.86 n bits ) . we present a high performance architecture that is easy to parallelize and scales well to very large data sets encountered in internet search applications . experimental results on a one billion url dataset obtained from live search crawl data , show that the proposed algorithm ( a ) finds an mphf for one billion urls in less than 4 minutes , and ( b ) requires only 6.86 bits\/key for the description of h. 
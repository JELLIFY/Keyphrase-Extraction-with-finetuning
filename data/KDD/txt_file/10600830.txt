ensemble pruning via individual contribution ordering an ensemble is a set of learned models that make decisions collectively . although an ensemble is usually more accurate than a single learner , existing ensemble methods often tend to construct unnecessarily large ensembles , which increases the memory consumption and computational cost . ensemble pruning tackles this problem by selecting a subset of ensemble members to form subensembles that are subject to less resource consumption and response time with accuracy that is similar to or better than the original ensemble . in this paper , we analyze the accuracy\/diversity trade-off and prove that classifiers that are more accurate and make more predictions in the minority group are more important for subensemble construction . based on the gained insights , a heuristic metric that considers both accuracy and diversity is proposed to explicitly evaluate each individual classifier 's contribution to the whole ensemble . by incorporating ensemble members in decreasing order of their contributions , subensembles are formed such that users can select the top $ p $ percent of ensemble members , depending on their resource availability and tolerable waiting time , for predictions . experimental results on 26 uci data sets show that subensembles formed by the proposed epic ( ensemble pruning via individual contribution ordering ) algorithm outperform the original ensemble and a state-of-the-art ensemble pruning method , orientation ordering ( oo ) .
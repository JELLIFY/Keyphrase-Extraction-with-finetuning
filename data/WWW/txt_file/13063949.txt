video summarization via transferrable structured learning it is well-known that textual information such as video transcripts and video reviews can significantly enhance the performance of video summarization algorithms . unfortunately , many videos on the web such as those from the popular video sharing site youtube do not have useful textual information . the goal of this paper is to propose a transfer learning framework for video summarization : in the training process both the video features and textual features are exploited to train a summarization algorithm while for summarizing a new video only its video features are utilized . the basic idea is to explore the transferability between videos and their corresponding textual information . based on the assumption that video features and textual features are highly correlated with each other , we can transfer textual information into knowledge on summarization using video information only . in particular , we formulate the video summarization problem as that of learning a mapping from a set of shots of a video to a subset of the shots using the general framework of svm-based structured learning . textual information is transferred by encoding them into a set of constraints used in the structured learning process which tend to provide a more detailed and accurate characterization of the different subsets of shots . experimental results show significant performance improvement of our approach and demonstrate the utility of textual information for enhancing video summarization . 
a contextual-bandit approach to personalized news article recommendation personalized web services strive to adapt their services ( advertisements , news articles , etc. ) to individual users by making use of both content and user information . despite a few recent advances , this problem remains challenging for at least two reasons . first , web service is featured with dynamically changing pools of content , rendering traditional collaborative filtering methods inapplicable . second , the scale of most web services of practical interest calls for solutions that are both fast in learning and computation . in this work , we model personalized recommendation of news articles as a contextual bandit problem , a principled approach in which a learning algorithm sequentially selects articles to serve users based on contextual information about the users and articles , while simultaneously adapting its article-selection strategy based on user-click feedback to maximize total user clicks . the contributions of this work are three-fold . first , we propose a new , general contextual bandit algorithm that is computationally efficient and well motivated from learning theory . second , we argue that any bandit algorithm can be reliably evaluated offline using previously recorded random traffic . finally , using this offline evaluation method , we successfully applied our new algorithm to a yahoo ! front page today module dataset containing over 33 million events . results showed a 12.5 % click lift compared to a standard context-free bandit algorithm , and the advantage becomes even greater when data gets more scarce . 
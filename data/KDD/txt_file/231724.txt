adversarial classification essentially all data mining algorithms assume that the data-generating process is independent of the data miner 's activities . however , in many domains , including spam detection , intrusion detection , fraud detection , surveillance and counter-terrorism , this is far from the case : the data is actively manipulated by an adversary seeking to make the classifier produce false negatives . in these domains , the performance of a classifier can degrade rapidly after it is deployed , as the adversary learns to defeat it . currently the only solution to this is repeated , manual , ad hoc reconstruction of the classifier . in this paper we develop a formal framework and algorithms for this problem . we view classification as a game between the classifier and the adversary , and produce a classifier that is optimal given the adversary 's optimal strategy . experiments in a spam detection domain show that this approach can greatly outperform a classifier learned in the standard way , and ( within the parameters of the problem ) automatically adapt the classifier to the adversary 's evolving manipulations .
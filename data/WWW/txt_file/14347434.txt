intelligent crawling of web applications for web archiving the steady growth of the world wide web raises challenges regarding the preservation of meaningful web data . tools used currently by web archivists blindly crawl and store web pages found while crawling , disregarding the kind of web site currently accessed ( which leads to suboptimal crawling strategies ) and whatever structured content is contained in web pages ( which results in page-level archives whose content is hard to exploit ) . we focus in this phd work on the crawling and archiving of publicly accessible web applications , especially those of the social web . a web application is any application that uses web standards such as html and http to publish information on the web , accessible by web browsers . examples include web forums , social networks , geolocation services , etc. . we claim that the best strategy to crawl these applications is to make the web crawler aware of the kind of application currently processed , allowing it to refine the list of urls to process , and to annotate the archive with information about the structure of crawled content . we add adaptive characteristics to an archival web crawler : being able to identify when a web page belongs to a given web application and applying the appropriate crawling and content extraction methodology . 
csurf : a context-driven non-visual web-browser web sites are designed for graphical mode of interaction . sighted users can `` cut to the chase '' and quickly identify relevant information in web pages . on the contrary , individuals with visual disabilities have to use screen-readers tobrowse the web . as screen-readers process pages sequentially and read through everything , web browsing can become strenuous and time-consuming . although , the use ofshortcuts and searching offers some improvements , the problem still remains . in this paper , we address the problemof information overload in non-visual web access using thenotion of context . our prototype system , csurf , embodyingor approach , provides the usual features of a screen-reader . however , when a user follows a link , csurf captures thecontext of the link using a simple topic-boundary detectiontechnique , and uses it to identify relevant information onthe next page with the help of a support vector machine , astatistical machine-learning model . then , csurf reads the web page starting from the most relevant section , identifiedby the model . we conducted a series experiments to evaluate the performance of csurf against the state-of-the-artscreen-reader , jaws . our results show that the use of context can potentially save browsing time and substantiallyimprove browsing experience of visually disabled people . 
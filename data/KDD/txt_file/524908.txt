mining distance-based outliers from large databases in any metric space let r be a set of objects . an object o âˆˆ r is an outlier , if there exist less than k objects in r whose distances to o are at most r. the values of k , r , and the distance metric are provided by a user at the run time . the objective is to return all outliers with the smallest i\/o cost . this paper considers a generic version of the problem , where no information is available for outlier computation , except for objects ' mutual distances . we prove an upper bound for the memory consumption which permits the discovery of all outliers by scanning the dataset 3 times . the upper bound turns out to be extremely low in practice , e.g. , less than 1 % of r. since the actual memory capacity of a realistic dbms is typically larger , we develop a novel algorithm , which integrates our theoretical findings with carefully-designed heuristics that leverage the additional memory to improve i\/o efficiency . our technique reports all outliers by scanning the dataset at most twice ( in some cases , even once ) , and significantly outperforms the existing solutions by a factor up to an order of magnitude .
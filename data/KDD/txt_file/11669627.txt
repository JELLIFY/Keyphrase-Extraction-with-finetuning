the offset tree for learning with partial labels we present an algorithm , called the offset tree , for learning to make decisions in situations where the payoff of only one choice is observed , rather than all choices . the algorithm reduces this setting to binary classification , allowing one to reuse any existing , fully supervised binary classification algorithm in this partial information setting . we show that the offset tree is an optimal reduction to binary classification . in particular , it has regret at most ( k-1 ) times the regret of the binary classifier it uses ( where k is the number of choices ) , and no reduction to binary classification can do better . this reduction is also computationally optimal , both at training and test time , requiring just o ( log2 k ) work to train on an example or make a prediction . experiments with the offset tree show that it generally performs better than several alternative approaches .
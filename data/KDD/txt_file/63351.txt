adversarial learning many classification tasks , such as spam filtering , intrusion detection , and terrorism detection , are complicated by an adversary who wishes to avoid detection . previous work on adversarial classification has made the unrealistic assumption that the attacker has perfect knowledge of the classifier ( 2 ) . in this paper , we introduce the adversarial classifier reverse engineering ( acre ) learning problem , the task of learning sufficient information about a classifier to construct adversarial attacks . we present efficient algorithms for reverse engineering linear classifiers with either continuous or boolean features and demonstrate their effectiveness using real data from the domain of spam filtering .
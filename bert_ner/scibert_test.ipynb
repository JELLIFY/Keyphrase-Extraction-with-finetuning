{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python3 train.py --finetuning --logdir finetuned_by_WWW --trainset /home/cilab/LabMembers/YS/WWW/finetuning/train.txt --validset /home/cilab/LabMembers/YS/WWW/finetuning/valid.txt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from data_load import NerDataset, pad, VOCAB, tag2idx, idx2tag\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, iterator):\n",
    "    model.eval()\n",
    "\n",
    "    Words, Is_heads, Tags, Y, Y_hat = [], [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(iterator)):\n",
    "            words, x, is_heads, tags, y, seqlens = batch\n",
    "\n",
    "            _, _, y_hat = model(x, y)  # y_hat: (N, T)\n",
    "\n",
    "            Words.extend(words)\n",
    "            Is_heads.extend(is_heads)\n",
    "            Tags.extend(tags)\n",
    "            Y.extend(y.numpy().tolist())\n",
    "            Y_hat.extend(y_hat.cpu().numpy().tolist())\n",
    "\n",
    "    ## gets results and save\n",
    "    with open(\"temp\", 'w') as fout:\n",
    "        for words, is_heads, tags, y_hat in zip(Words, Is_heads, Tags, Y_hat):\n",
    "            y_hat = [hat for head, hat in zip(is_heads, y_hat) if head == 1]\n",
    "            preds = [idx2tag[hat] for hat in y_hat]\n",
    "            assert len(preds)==len(words.split())==len(tags.split())\n",
    "            for w, t, p in zip(words.split()[1:-1], tags.split()[1:-1], preds[1:-1]):\n",
    "                fout.write(f\"{w} {t} {p}\\n\")\n",
    "            fout.write(\"\\n\")\n",
    "\n",
    "    ## calc metric\n",
    "    y_true =  np.array([tag2idx[line.split()[1]] for line in open(\"temp\", 'r').read().splitlines() if len(line) > 0])\n",
    "    y_pred =  np.array([tag2idx[line.split()[2]] for line in open(\"temp\", 'r').read().splitlines() if len(line) > 0])\n",
    "\n",
    "    num_proposed = len(y_pred[y_pred>1])\n",
    "    num_correct = (np.logical_and(y_true==y_pred, y_true>1)).astype(np.int).sum()\n",
    "    num_gold = len(y_true[y_true>1])\n",
    "\n",
    "    print(f\"num_proposed:{num_proposed}\")\n",
    "    print(f\"num_correct:{num_correct}\")\n",
    "    print(f\"num_gold:{num_gold}\")\n",
    "    try:\n",
    "        precision = num_correct / num_proposed\n",
    "    except ZeroDivisionError:\n",
    "        precision = 1.0\n",
    "\n",
    "    try:\n",
    "        recall = num_correct / num_gold\n",
    "    except ZeroDivisionError:\n",
    "        recall = 1.0\n",
    "\n",
    "    try:\n",
    "        f1 = 2*precision*recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        if precision*recall==0:\n",
    "            f1=1.0\n",
    "        else:\n",
    "            f1=0\n",
    "\n",
    "    os.remove(\"temp\")\n",
    "\n",
    "    print(\"precision=%.2f\"%precision)\n",
    "    print(\"recall=%.2f\"%recall)\n",
    "    print(\"f1=%.2f\"%f1)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, top_rnns=False, vocab_size=None, device='cpu', finetuning=False, model='bert-base-cased'):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model)\n",
    "\n",
    "        self.top_rnns=top_rnns\n",
    "        if top_rnns:\n",
    "            self.rnn = nn.LSTM(bidirectional=True, num_layers=2, input_size=768, hidden_size=768//2, batch_first=True)\n",
    "        self.fc = nn.Linear(768, vocab_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.finetuning = finetuning\n",
    "\n",
    "    def forward(self, x, y, ):\n",
    "        '''\n",
    "        x: (N, T). int64\n",
    "        y: (N, T). int64\n",
    "\n",
    "        Returns\n",
    "        enc: (N, T, VOCAB)\n",
    "        '''\n",
    "        x = x.to(self.device)\n",
    "        y = y.to(self.device)\n",
    "\n",
    "        if self.training and self.finetuning:\n",
    "            # print(\"->bert.train()\")\n",
    "            self.bert.train()\n",
    "            encoded_layers, _ = self.bert(x)\n",
    "            enc = encoded_layers[-1]\n",
    "        else:\n",
    "            self.bert.eval()\n",
    "            with torch.no_grad():\n",
    "                encoded_layers, _ = self.bert(x)\n",
    "                enc = encoded_layers[-1]\n",
    "\n",
    "        if self.top_rnns:\n",
    "            enc, _ = self.rnn(enc)\n",
    "        logits = self.fc(enc)\n",
    "        y_hat = logits.argmax(-1)\n",
    "\n",
    "        return logits, y, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt_data/models/scibert_Inspec_p/1.pt', '/mnt_data/models/scibert_Inspec_p/4.pt', '/mnt_data/models/scibert_Inspec_p/3.pt', '/mnt_data/models/scibert_Inspec_p/2.pt', '/mnt_data/models/scibert_Inspec_p/5.pt']\n",
      "/mnt_data/models/scibert_Inspec_p/1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [00:16<00:00, 48.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_proposed:1718\n",
      "num_correct:934\n",
      "num_gold:2430\n",
      "precision=0.54\n",
      "recall=0.38\n",
      "f1=0.45\n",
      "/mnt_data/models/scibert_Inspec_p/4.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [00:16<00:00, 48.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_proposed:2526\n",
      "num_correct:1211\n",
      "num_gold:2430\n",
      "precision=0.48\n",
      "recall=0.50\n",
      "f1=0.49\n",
      "/mnt_data/models/scibert_Inspec_p/3.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [00:16<00:00, 48.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_proposed:2351\n",
      "num_correct:1205\n",
      "num_gold:2430\n",
      "precision=0.51\n",
      "recall=0.50\n",
      "f1=0.50\n",
      "/mnt_data/models/scibert_Inspec_p/2.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [00:16<00:00, 48.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_proposed:2389\n",
      "num_correct:1207\n",
      "num_gold:2430\n",
      "precision=0.51\n",
      "recall=0.50\n",
      "f1=0.50\n",
      "/mnt_data/models/scibert_Inspec_p/5.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 790/790 [00:15<00:00, 49.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_proposed:2225\n",
      "num_correct:1114\n",
      "num_gold:2430\n",
      "precision=0.50\n",
      "recall=0.46\n",
      "f1=0.48\n",
      "best model f1: 0.5040786446350136\n",
      " model name: /mnt_data/models/scibert_Inspec_p/3.pt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"./bert_model/scibert_scivocab_uncased/vocab.txt\", do_lower_case=False)\n",
    "\n",
    "test_path = \"/home/cilab/LabMembers/YS/WWW/finetuning/test.txt\"\n",
    "\n",
    "eval_dataset = NerDataset(test_path, tokenizer)\n",
    "\n",
    "eval_iter = data.DataLoader(dataset=eval_dataset,\n",
    "                             batch_size=4,\n",
    "                             shuffle=False,\n",
    "                             num_workers=4,\n",
    "                             collate_fn=pad)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "checkpoints_path = \"/mnt_data/models/scibert_WWW/*\"\n",
    "checkpoints = [ck for ck in glob.glob(checkpoints_path) if '.pt' in ck]\n",
    "max_f1 = 0\n",
    "max_pt = \"\"\n",
    "print(checkpoints)\n",
    "for ck in checkpoints:\n",
    "    print(ck)\n",
    "    model = Net(False, len(VOCAB), device, False, './bert_model/scibert_scivocab_uncased/').cuda()\n",
    "    #model = nn.DataParallel(model)\n",
    "    checkpoint = torch.load(ck)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "    #model = model.module.cuda()\n",
    "    precision, recall, f1 = eval(model, eval_iter)\n",
    "    if max_f1 < f1:\n",
    "        max_f1 = f1\n",
    "        max_pt = ck\n",
    "print(\"best model f1: {}\\n model name: {}\".format(max_f1, max_pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

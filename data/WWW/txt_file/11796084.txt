sourcerank : relevance and trust assessment for deep web sources based on inter-source agreement one immediate challenge in searching the deep web databases is source selection - i.e. selecting the most relevant web databases for answering a given query . the existing database selection methods ( both text and relational ) assess the source quality based on the query-similarity-based relevance assessment . when applied to the deep web these methods have two deficiencies . first is that the methods are agnostic to the correctness ( trustworthiness ) of the sources . secondly , the query based relevance does not consider the importance of the results . these two considerations are essential for the open collections like the deep web . since a number of sources provide answers to any query , we conjuncture that the agreements between these answers are likely to be helpful in assessing the importance and the trustworthiness of the sources . we compute the agreement between the sources as the agreement of the answers returned . while computing the agreement , we also measure and compensate for possible collusion between the sources . this adjusted agreement is modeled as a graph with sources at the vertices . on this agreement graph , a quality score of a source that we call sourcerank , is calculated as the stationary visit probability of a random walk . we evaluate sourcerank in multiple domains , including sources in google base , with sizes up to 675 sources . we demonstrate that the sourcerank tracks source corruption . further , our relevance evaluations show that sourcerank improves precision by 22-60 % over the google base and the other baseline methods . sourcerank has been implemented in a system called factal . 
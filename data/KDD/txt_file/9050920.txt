training linear svms in linear time linear support vector machines ( svms ) have become one of the most prominent machine learning techniques for high-dimensional sparse data commonly encountered in applications like text classification , word-sense disambiguation , and drug design . these applications involve a large number of examples n as well as a large number of features n , while each example has only s ( ( n non-zero features . this paper presents a cutting plane algorithm for training linear svms that provably has training time 0 ( s , n ) for classification problems and o ( sn log ( n ) ) for ordinal regression problems . the algorithm is based on an alternative , but equivalent formulation of the svm optimization problem . empirically , the cutting-plane algorithm is several orders of magnitude faster than decomposition methods like svm light for large datasets .
data mining with sparse grids using simplicial basis functions recently we presented a new approach ( 18 ) to the classification problem arising in data mining . it is based on the regularization network approach but , in contrast to other methods which employ ansatz functions associated to data points , we use a grid in the usually high-dimensional feature space for the minimization process . to cope with the curse of dimensionality , we employ sparse grids ( 49 ) . thus , only o ( hn-1nd-1 ) instead of o ( hn-d ) grid points and unknowns are involved . here d denotes the dimension of the feature space and hn = 2-n gives the mesh size . we use the sparse grid combination technique ( 28 ) where the classification problem is discretized and solved on a sequence of conventional grids with uniform mesh sizes in each dimension . the sparse grid solution is then obtained by linear combination . in contrast to our former work , where d-linear functions were used , we now apply linear basis functions based on a simplicial discretization . this allows to handle more dimensions and the algorithm needs less operations per data point . we describe the sparse grid combination technique for the classification problem , give implementational details and discuss the complexity of the algorithm . it turns out that the method scales linearly with the number of given data points . finally we report on the quality of the classifier built by our new method on data sets with up to 10 dimensions . it turns out that our new method achieves correctness rates which are competitive to that of the best existing methods .
mining complex models from arbitrarily large databases in constant time in this paper we propose a scaling-up method that is applicable to essentially any induction algorithm based on discrete search . the result of applying the method to an algorithm is that its running time becomes independent of the size of the database , while the decisions made are essentially identical to those that would be made given infinite data . the method works within pre-specified memory limits and , as long as the data is iid , only requires accessing it sequentially . it gives anytime results , and can be used to produce batch , stream , time-changing and active-learning versions of an algorithm . we apply the method to learning bayesian networks , developing an algorithm that is faster than previous ones by orders of magnitude , while achieving essentially the same predictive performance . we observe these gains on a series of large databases `` generated from benchmark networks , on the kdd cup 2000 e-commerce data , and on a web log containing 100 million requests .
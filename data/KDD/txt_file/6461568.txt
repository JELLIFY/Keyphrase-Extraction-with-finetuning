a general approach to incorporate data quality matrices into data mining algorithms data quality is a central issue for many information-oriented organizations . recent advances in the data quality field reflect the view that a database is the product of a manufacturing process . while routine errors , such as non-existent zip codes , can be detected and corrected using traditional data cleansing tools , many errors systemic to the manufacturing process can not be addressed . therefore , the product of the data manufacturing process is an imprecise recording of information about the entities of interest ( i.e. customers , transactions or assets ) . in this way , the database is only one ( flawed ) version of the entities it is supposed to represent . quality assurance systems such as motorola 's six-sigma and other continuous improvement methods document the data manufacturing process 's shortcomings . a widespread method of documentation is quality matrices . in this paper , we explore the use of the readily available data quality matrices for the data mining classification task . we first illustrate that if we do not factor in these quality matrices , then our results for prediction are sub-optimal . we then suggest a general-purpose ensemble approach that perturbs the data according to these quality matrices to improve the predictive accuracy and show the improvement is due to a reduction in variance .
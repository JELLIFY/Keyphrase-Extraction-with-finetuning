making every bit count : fast nonlinear axis scaling existing axis scaling and dimensionality methods focus on preserving structure , usually determined via the euclidean distance . in other words , they inherently assume that the euclidean distance is already correct . we instead propose a novel nonlinear approach driven by an information-theoretic viewpoint , which we show is also strongly linked to intrinsic dimensionality , or degrees of freedom ; and uniformity . nonlinear transformations based on common probability distributions , combined with information-driven selection , simultaneously reduce the number of dimensions required and increase the value of those we retain . experiments on real data confirm that this approach reveals correlations , finds novel attributes , and scales well .
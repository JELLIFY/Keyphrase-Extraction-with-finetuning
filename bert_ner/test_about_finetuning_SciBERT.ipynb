{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from model_scibert import Net\n",
    "from data_load import NerDataset, pad, VOCAB, tokenizer, tag2idx, idx2tag\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "\n",
    "class Arg():\n",
    "    def __init__(self, check_path):\n",
    "        self.checkpoint = check_path\n",
    "        self.batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, iterator):\n",
    "    model.eval()\n",
    "\n",
    "    Words, Is_heads, Tags, Y, Y_hat = [], [], [], [], []\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            words, x, is_heads, tags, y, seqlens = batch\n",
    "\n",
    "            _, _, y_hat = model(x, y)  # y_hat: (N, T)\n",
    "\n",
    "            Words.extend(words)\n",
    "            Is_heads.extend(is_heads)\n",
    "            Tags.extend(tags)\n",
    "            Y.extend(y.numpy().tolist())\n",
    "            Y_hat.extend(y_hat.cpu().numpy().tolist())\n",
    "\n",
    "    ## gets results and save\n",
    "    with open(\"temp\", 'w') as fout:\n",
    "        for words, is_heads, tags, y_hat in zip(Words, Is_heads, Tags, Y_hat):\n",
    "            y_hat = [hat for head, hat in zip(is_heads, y_hat) if head == 1]\n",
    "            preds = [idx2tag[hat] for hat in y_hat]\n",
    "            assert len(preds)==len(words.split())==len(tags.split())\n",
    "            for w, t, p in zip(words.split()[1:-1], tags.split()[1:-1], preds[1:-1]):\n",
    "                fout.write(f\"{w} {t} {p}\\n\")\n",
    "            fout.write(\"\\n\")\n",
    "\n",
    "    ## calc metric\n",
    "    y_true =  np.array([tag2idx[line.split()[1]] for line in open(\"temp\", 'r').read().splitlines() if len(line) > 0])\n",
    "    y_pred =  np.array([tag2idx[line.split()[2]] for line in open(\"temp\", 'r').read().splitlines() if len(line) > 0])\n",
    "\n",
    "    num_proposed = len(y_pred[y_pred>1])\n",
    "    num_correct = (np.logical_and(y_true==y_pred, y_true>1)).astype(np.int).sum()\n",
    "    num_gold = len(y_true[y_true>1])\n",
    "\n",
    "    print(f\"num_proposed:{num_proposed}\")\n",
    "    print(f\"num_correct:{num_correct}\")\n",
    "    print(f\"num_gold:{num_gold}\")\n",
    "    try:\n",
    "        precision = num_correct / num_proposed\n",
    "    except ZeroDivisionError:\n",
    "        precision = 1.0\n",
    "\n",
    "    try:\n",
    "        recall = num_correct / num_gold\n",
    "    except ZeroDivisionError:\n",
    "        recall = 1.0\n",
    "\n",
    "    try:\n",
    "        f1 = 2*precision*recall / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        if precision*recall==0:\n",
    "            f1=1.0\n",
    "        else:\n",
    "            f1=0\n",
    "\n",
    "    os.remove(\"temp\")\n",
    "\n",
    "    print(\"precision=%.2f\"%precision)\n",
    "    print(\"recall=%.2f\"%recall)\n",
    "    print(\"f1=%.2f\"%f1)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt_data/sci_WWW/5e-5/1.P0.47_R0.33_F0.39', '/mnt_data/sci_WWW/5e-5/1.pt', '/mnt_data/sci_WWW/5e-5/2.P0.57_R0.18_F0.27', '/mnt_data/sci_WWW/5e-5/2.pt', '/mnt_data/sci_WWW/5e-5/3.P0.45_R0.38_F0.41', '/mnt_data/sci_WWW/5e-5/3.pt', '/mnt_data/sci_WWW/5e-5/4.P0.42_R0.35_F0.38', '/mnt_data/sci_WWW/5e-5/4.pt', '/mnt_data/sci_WWW/5e-5/5.P0.44_R0.37_F0.40', '/mnt_data/sci_WWW/5e-5/5.pt']\n",
      "/mnt_data/sci_WWW/5e-5/1.pt\n",
      "/mnt_data/sci_WWW/5e-5/2.pt\n",
      "/mnt_data/sci_WWW/5e-5/3.pt\n",
      "/mnt_data/sci_WWW/5e-5/4.pt\n",
      "/mnt_data/sci_WWW/5e-5/5.pt\n",
      "load check point of model...\n",
      "<data_load.NerDataset object at 0x7f40b5572550>\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-5/1.pt\n",
      "num_proposed:1260\n",
      "num_correct:644\n",
      "num_gold:1738\n",
      "precision=0.51\n",
      "recall=0.37\n",
      "f1=0.43\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-5/2.pt\n",
      "num_proposed:572\n",
      "num_correct:362\n",
      "num_gold:1738\n",
      "precision=0.63\n",
      "recall=0.21\n",
      "f1=0.31\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-5/3.pt\n",
      "num_proposed:1500\n",
      "num_correct:678\n",
      "num_gold:1738\n",
      "precision=0.45\n",
      "recall=0.39\n",
      "f1=0.42\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-5/4.pt\n",
      "num_proposed:1555\n",
      "num_correct:669\n",
      "num_gold:1738\n",
      "precision=0.43\n",
      "recall=0.38\n",
      "f1=0.41\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-5/5.pt\n",
      "num_proposed:1561\n",
      "num_correct:669\n",
      "num_gold:1738\n",
      "precision=0.43\n",
      "recall=0.38\n",
      "f1=0.41\n",
      "\n",
      "\n",
      "1.pt : F1_Score : 0.4296197464976651\n",
      "['0.43', '0.31', '0.42', '0.41', '0.41']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    check_lists=[]\n",
    "    dir_list = glob.glob(\"/mnt_data/sci_WWW/5e-5/*\")\n",
    "    dir_list.sort()\n",
    "    dictionary = {}\n",
    "    checkpoint = []\n",
    "    print(dir_list)\n",
    "    for directory in dir_list:\n",
    "        if directory.endswith('.pt'):\n",
    "            checkpoint.append(directory)\n",
    "\n",
    "    for i in checkpoint:\n",
    "        print(i)\n",
    "                \n",
    "    testset = \"/home/cilab/LabMembers/YS/WWW/finetuning/test.txt\"\n",
    "    \n",
    "    print(\"load check point of model...\")\n",
    "\n",
    "    model = Net(False, len(VOCAB), 'cpu', False)\n",
    "    eval_dataset = NerDataset(testset)\n",
    "    print(eval_dataset)\n",
    "    eval_iter = data.DataLoader(dataset=eval_dataset,\n",
    "                                     batch_size=8,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=4,\n",
    "                                     collate_fn=pad)\n",
    "    max_f1 = 0\n",
    "    max_pt = \"\"\n",
    "    f1_list = []\n",
    "    for check in checkpoint:\n",
    "        print(\"\\nCheck Point : \",check)\n",
    "        hp = Arg(check)\n",
    "        checkpoint = torch.load(hp.checkpoint)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "\n",
    "        precision, recall, f1 = eval(model, eval_iter)\n",
    "        f1_list.append(format(f1, '.2f'))\n",
    "        if max_f1<f1:\n",
    "            max_f1 = f1\n",
    "            max_pt = check\n",
    "    print(\"\\n\\n{} : F1_Score : {}\".format(max_pt.split('/')[-1], max_f1))\n",
    "    print(f1_list)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt_data/sci_WWW/5e-6/1.pt\n",
      "/mnt_data/sci_WWW/5e-6/2.pt\n",
      "/mnt_data/sci_WWW/5e-6/3.pt\n",
      "/mnt_data/sci_WWW/5e-6/4.pt\n",
      "/mnt_data/sci_WWW/5e-6/5.pt\n",
      "load check point of model...\n",
      "<data_load.NerDataset object at 0x7f4150573d30>\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-6/1.pt\n",
      "num_proposed:623\n",
      "num_correct:341\n",
      "num_gold:1738\n",
      "precision=0.55\n",
      "recall=0.20\n",
      "f1=0.29\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-6/2.pt\n",
      "num_proposed:778\n",
      "num_correct:427\n",
      "num_gold:1738\n",
      "precision=0.55\n",
      "recall=0.25\n",
      "f1=0.34\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-6/3.pt\n",
      "num_proposed:983\n",
      "num_correct:530\n",
      "num_gold:1738\n",
      "precision=0.54\n",
      "recall=0.30\n",
      "f1=0.39\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-6/4.pt\n",
      "num_proposed:1265\n",
      "num_correct:636\n",
      "num_gold:1738\n",
      "precision=0.50\n",
      "recall=0.37\n",
      "f1=0.42\n",
      "\n",
      "Check Point :  /mnt_data/sci_WWW/5e-6/5.pt\n",
      "num_proposed:1248\n",
      "num_correct:621\n",
      "num_gold:1738\n",
      "precision=0.50\n",
      "recall=0.36\n",
      "f1=0.42\n",
      "\n",
      "\n",
      "4.pt : F1_Score : 0.4235764235764236\n",
      "['0.29', '0.34', '0.39', '0.42', '0.42']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    check_lists=[]\n",
    "    dir_list = glob.glob(\"/mnt_data/sci_WWW/5e-6/*\")\n",
    "    dir_list.sort()\n",
    "    dictionary = {}\n",
    "    checkpoint = []\n",
    "    for directory in dir_list:\n",
    "        if directory.endswith('.pt'):\n",
    "            checkpoint.append(directory)\n",
    "\n",
    "    for i in checkpoint:\n",
    "        print(i)\n",
    "                \n",
    "    testset = \"/home/cilab/LabMembers/YS/WWW/finetuning/test.txt\"\n",
    "    \n",
    "    print(\"load check point of model...\")\n",
    "\n",
    "    model = Net(False, len(VOCAB), 'cpu', False)\n",
    "    eval_dataset = NerDataset(testset)\n",
    "    print(eval_dataset)\n",
    "    eval_iter = data.DataLoader(dataset=eval_dataset,\n",
    "                                     batch_size=8,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=4,\n",
    "                                     collate_fn=pad)\n",
    "    max_f1 = 0\n",
    "    max_pt = \"\"\n",
    "    f1_list = []\n",
    "    for check in checkpoint:\n",
    "        print(\"\\nCheck Point : \",check)\n",
    "        hp = Arg(check)\n",
    "        checkpoint = torch.load(hp.checkpoint)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "\n",
    "        precision, recall, f1 = eval(model, eval_iter)\n",
    "        f1_list.append(format(f1, '.2f'))\n",
    "        if max_f1<f1:\n",
    "            max_f1 = f1\n",
    "            max_pt = check\n",
    "    print(\"\\n\\n{} : F1_Score : {}\".format(max_pt.split('/')[-1], max_f1))\n",
    "    print(f1_list)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt_data/sci_KDD/5e-5/1.pt\n",
      "/mnt_data/sci_KDD/5e-5/2.pt\n",
      "/mnt_data/sci_KDD/5e-5/3.pt\n",
      "/mnt_data/sci_KDD/5e-5/4.pt\n",
      "/mnt_data/sci_KDD/5e-5/5.pt\n",
      "load check point of model...\n",
      "<data_load.NerDataset object at 0x7f40afd4ff98>\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-5/1.pt\n",
      "num_proposed:457\n",
      "num_correct:218\n",
      "num_gold:1121\n",
      "precision=0.48\n",
      "recall=0.19\n",
      "f1=0.28\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-5/2.pt\n",
      "num_proposed:587\n",
      "num_correct:254\n",
      "num_gold:1121\n",
      "precision=0.43\n",
      "recall=0.23\n",
      "f1=0.30\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-5/3.pt\n",
      "num_proposed:820\n",
      "num_correct:368\n",
      "num_gold:1121\n",
      "precision=0.45\n",
      "recall=0.33\n",
      "f1=0.38\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-5/4.pt\n",
      "num_proposed:930\n",
      "num_correct:388\n",
      "num_gold:1121\n",
      "precision=0.42\n",
      "recall=0.35\n",
      "f1=0.38\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-5/5.pt\n",
      "num_proposed:675\n",
      "num_correct:316\n",
      "num_gold:1121\n",
      "precision=0.47\n",
      "recall=0.28\n",
      "f1=0.35\n",
      "\n",
      "\n",
      "3.pt : F1_Score : 0.3791859866048429\n",
      "['0.28', '0.30', '0.38', '0.38', '0.35']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    check_lists=[]\n",
    "    dir_list = glob.glob(\"/mnt_data/sci_KDD/5e-5/*\")\n",
    "    dir_list.sort()\n",
    "    dictionary = {}\n",
    "    checkpoint = []\n",
    "    for directory in dir_list:\n",
    "        if directory.endswith('.pt'):\n",
    "            checkpoint.append(directory)\n",
    "\n",
    "    for i in checkpoint:\n",
    "        print(i)\n",
    "                \n",
    "    testset = \"/home/cilab/LabMembers/YS/KDD/finetuning/test.txt\"\n",
    "    \n",
    "    print(\"load check point of model...\")\n",
    "\n",
    "    model = Net(False, len(VOCAB), 'cpu', False)\n",
    "    eval_dataset = NerDataset(testset)\n",
    "    print(eval_dataset)\n",
    "    eval_iter = data.DataLoader(dataset=eval_dataset,\n",
    "                                     batch_size=8,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=4,\n",
    "                                     collate_fn=pad)\n",
    "    max_f1 = 0\n",
    "    max_pt = \"\"\n",
    "    f1_list = []\n",
    "    for check in checkpoint:\n",
    "        print(\"\\nCheck Point : \",check)\n",
    "        hp = Arg(check)\n",
    "        checkpoint = torch.load(hp.checkpoint)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "\n",
    "        precision, recall, f1 = eval(model, eval_iter)\n",
    "        f1_list.append(format(f1, '.2f'))\n",
    "        if max_f1<f1:\n",
    "            max_f1 = f1\n",
    "            max_pt = check\n",
    "    print(\"\\n\\n{} : F1_Score : {}\".format(max_pt.split('/')[-1], max_f1))\n",
    "    print(f1_list)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt_data/sci_KDD/5e-6/1.pt\n",
      "/mnt_data/sci_KDD/5e-6/2.pt\n",
      "/mnt_data/sci_KDD/5e-6/3.pt\n",
      "/mnt_data/sci_KDD/5e-6/4.pt\n",
      "/mnt_data/sci_KDD/5e-6/5.pt\n",
      "load check point of model...\n",
      "<data_load.NerDataset object at 0x7f40afd14cf8>\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-6/1.pt\n",
      "num_proposed:270\n",
      "num_correct:111\n",
      "num_gold:1121\n",
      "precision=0.41\n",
      "recall=0.10\n",
      "f1=0.16\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-6/2.pt\n",
      "num_proposed:366\n",
      "num_correct:156\n",
      "num_gold:1121\n",
      "precision=0.43\n",
      "recall=0.14\n",
      "f1=0.21\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-6/3.pt\n",
      "num_proposed:614\n",
      "num_correct:252\n",
      "num_gold:1121\n",
      "precision=0.41\n",
      "recall=0.22\n",
      "f1=0.29\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-6/4.pt\n",
      "num_proposed:912\n",
      "num_correct:361\n",
      "num_gold:1121\n",
      "precision=0.40\n",
      "recall=0.32\n",
      "f1=0.36\n",
      "\n",
      "Check Point :  /mnt_data/sci_KDD/5e-6/5.pt\n",
      "num_proposed:784\n",
      "num_correct:339\n",
      "num_gold:1121\n",
      "precision=0.43\n",
      "recall=0.30\n",
      "f1=0.36\n",
      "\n",
      "\n",
      "5.pt : F1_Score : 0.3559055118110236\n",
      "['0.16', '0.21', '0.29', '0.36', '0.36']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    check_lists=[]\n",
    "    dir_list = glob.glob(\"/mnt_data/sci_KDD/5e-6/*\")\n",
    "    dir_list.sort()\n",
    "    dictionary = {}\n",
    "    checkpoint = []\n",
    "    for directory in dir_list:\n",
    "        if directory.endswith('.pt'):\n",
    "            checkpoint.append(directory)\n",
    "\n",
    "    for i in checkpoint:\n",
    "        print(i)\n",
    "                \n",
    "    testset = \"/home/cilab/LabMembers/YS/KDD/finetuning/test.txt\"\n",
    "    \n",
    "    print(\"load check point of model...\")\n",
    "\n",
    "    model = Net(False, len(VOCAB), 'cpu', False)\n",
    "    eval_dataset = NerDataset(testset)\n",
    "    print(eval_dataset)\n",
    "    eval_iter = data.DataLoader(dataset=eval_dataset,\n",
    "                                     batch_size=8,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=4,\n",
    "                                     collate_fn=pad)\n",
    "    max_f1 = 0\n",
    "    max_pt = \"\"\n",
    "    f1_list = []\n",
    "    for check in checkpoint:\n",
    "        print(\"\\nCheck Point : \",check)\n",
    "        hp = Arg(check)\n",
    "        checkpoint = torch.load(hp.checkpoint)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "\n",
    "        precision, recall, f1 = eval(model, eval_iter)\n",
    "        f1_list.append(format(f1, '.2f'))\n",
    "        if max_f1<f1:\n",
    "            max_f1 = f1\n",
    "            max_pt = check\n",
    "    print(\"\\n\\n{} : F1_Score : {}\".format(max_pt.split('/')[-1], max_f1))\n",
    "    print(f1_list)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt_data/sci_bert_Inspec/1.pt\n",
      "/mnt_data/sci_bert_Inspec/2.pt\n",
      "/mnt_data/sci_bert_Inspec/3.pt\n",
      "/mnt_data/sci_bert_Inspec/4.pt\n",
      "/mnt_data/sci_bert_Inspec/5.pt\n",
      "load check point of model...\n",
      "<data_load.NerDataset object at 0x7fd7f007e1d0>\n",
      "\n",
      "Check Point :  /mnt_data/sci_bert_Inspec/1.pt\n",
      "num_proposed:807\n",
      "num_correct:468\n",
      "num_gold:2430\n",
      "precision=0.58\n",
      "recall=0.19\n",
      "f1=0.29\n",
      "\n",
      "Check Point :  /mnt_data/sci_bert_Inspec/2.pt\n",
      "num_proposed:1952\n",
      "num_correct:915\n",
      "num_gold:2430\n",
      "precision=0.47\n",
      "recall=0.38\n",
      "f1=0.42\n",
      "\n",
      "Check Point :  /mnt_data/sci_bert_Inspec/3.pt\n",
      "num_proposed:1525\n",
      "num_correct:760\n",
      "num_gold:2430\n",
      "precision=0.50\n",
      "recall=0.31\n",
      "f1=0.38\n",
      "\n",
      "Check Point :  /mnt_data/sci_bert_Inspec/4.pt\n",
      "num_proposed:1604\n",
      "num_correct:789\n",
      "num_gold:2430\n",
      "precision=0.49\n",
      "recall=0.32\n",
      "f1=0.39\n",
      "\n",
      "Check Point :  /mnt_data/sci_bert_Inspec/5.pt\n",
      "num_proposed:2182\n",
      "num_correct:910\n",
      "num_gold:2430\n",
      "precision=0.42\n",
      "recall=0.37\n",
      "f1=0.39\n",
      "\n",
      "\n",
      "2.pt : F1_Score : 0.4176175262437243\n",
      "['0.29', '0.42', '0.38', '0.39', '0.39']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import glob\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    check_lists=[]\n",
    "    dir_list = glob.glob(\"/mnt_data/sci_bert_Inspec/*\")\n",
    "    dir_list.sort()\n",
    "    dictionary = {}\n",
    "    checkpoint = []\n",
    "    for directory in dir_list:\n",
    "        if directory.endswith('.pt'):\n",
    "            checkpoint.append(directory)\n",
    "\n",
    "    for i in checkpoint:\n",
    "        print(i)\n",
    "                \n",
    "    testset = \"/home/cilab/LabMembers/YS/Inspec/data/finetuning/test.txt\"\n",
    "    \n",
    "    print(\"load check point of model...\")\n",
    "\n",
    "    model = Net(False, len(VOCAB), 'cpu', False)\n",
    "    eval_dataset = NerDataset(testset)\n",
    "    print(eval_dataset)\n",
    "    eval_iter = data.DataLoader(dataset=eval_dataset,\n",
    "                                     batch_size=8,\n",
    "                                     shuffle=False,\n",
    "                                     num_workers=4,\n",
    "                                     collate_fn=pad)\n",
    "    max_f1 = 0\n",
    "    max_pt = \"\"\n",
    "    f1_list = []\n",
    "    for check in checkpoint:\n",
    "        print(\"\\nCheck Point : \",check)\n",
    "        hp = Arg(check)\n",
    "        checkpoint = torch.load(hp.checkpoint)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "\n",
    "        precision, recall, f1 = eval(model, eval_iter)\n",
    "        f1_list.append(format(f1, '.2f'))\n",
    "        if max_f1<f1:\n",
    "            max_f1 = f1\n",
    "            max_pt = check\n",
    "    print(\"\\n\\n{} : F1_Score : {}\".format(max_pt.split('/')[-1], max_f1))\n",
    "    print(f1_list)\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

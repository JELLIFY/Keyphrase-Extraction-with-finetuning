single-pass online learning : performance , voting schemes and online feature selection to learn concepts over massive data streams , it is essential to design inference and learning methods that operate in real time with limited memory . online learning methods such as perceptron or winnow are naturally suited to stream processing ; however , in practice multiple passes over the same training data are required to achieve accuracy comparable to state-of-the-art batch learners . in the current work we address the problem of training an on-line learner with a single passover the data . we evaluate several existing methods , and also propose a new modification of margin balanced winnow , which has performance comparable to linear svm . we also explore the effect of averaging , a.k.a. voting , on online learning . finally , we describe how the new modified margin balanced winnow algorithm can be naturally adapted to perform feature selection . this scheme performs comparably to widely-used batch feature selection methods like information gain or chi-square , with the advantage of being able to select features on-the-fly . taken together , these techniques allow single-pass online learning to be competitive with batch techniques , and still maintain the advantages of on-line learning .
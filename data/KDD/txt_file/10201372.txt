heterogeneous source consensus learning via decision propagation and negotiation nowadays , enormous amounts of data are continuously generated not only in massive scale , but also from different , sometimes conflicting , views . therefore , it is important to consolidate different concepts for intelligent decision making . for example , to predict the research areas of some people , the best results are usually achieved by combining and consolidating predictions obtained from the publication network , co-authorship network and the textual content of their publications . multiple supervised and unsupervised hypotheses can be drawn from these information sources , and negotiating their differences and consolidating decisions usually yields a much more accurate model due to the diversity and heterogeneity of these models . in this paper , we address the problem of `` consensus learning '' among competing hypotheses , which either rely on outside knowledge ( supervised learning ) or internal structure ( unsupervised clustering ) . we argue that consensus learning is an np-hard problem and thus propose to solve it by an efficient heuristic method . we construct a belief graph to first propagate predictions from supervised models to the unsupervised , and then negotiate and reach consensus among them . their final decision is further consolidated by calculating each model 's weight based on its degree of consistency with other models . experiments are conducted on 20 newsgroups data , cora research papers , dblp author-conference network , and yahoo ! movies datasets , and the results show that the proposed method improves the classification accuracy and the clustering quality measure ( nmi ) over the best base model by up to 10 % . furthermore , it runs in time proportional to the number of instances , which is very efficient for large scale data sets .
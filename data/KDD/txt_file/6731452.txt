regularized discriminant analysis for high dimensional , low sample size data linear and quadratic discriminant analysis have been used widely in many areas of data mining , machine learning , and bioinformatics . friedman proposed a compromise between linear and quadratic discriminant analysis , called regularized discriminant analysis ( rda ) , which has been shown to be more flexible in dealing with various class distributions . rda applies the regularization techniques by employing two regularization parameters , which are chosen to jointly maximize the classification performance . the optimal pair of parameters is commonly estimated via cross-validation from a set of candidate pairs . it is computationally prohibitive for high dimensional data , especially when the candidate set is large , which limits the applications of rda to low dimensional data . in this paper , a novel algorithm for rda is presented for high dimensional data . it can estimate the optimal regularization parameters from a large set of parameter candidates efficiently . experiments on a variety of datasets confirm the claimed theoretical estimate of the efficiency , and also show that , for a properly chosen pair of regularization parameters , rda performs favorably in classification , in comparison with other existing classification methods .
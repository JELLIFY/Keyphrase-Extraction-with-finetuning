a cross-collection mixture model for comparative text mining in this paper , we define and study a novel text mining problem , which we refer to as comparative text mining ( ctm ) . given a set of comparable text collections , the task of comparative text mining is to discover any latent common themes across all collections as well as summarize the similarity and differences of these collections along each common theme . this general problem subsumes many interesting applications , including business intelligence and opinion summarization . we propose a generative probabilistic mixture model for comparative text mining . the model simultaneously performs cross-collection clustering and within-collection clustering , and can be applied to an arbitrary set of comparable text collections . the model can be estimated efficiently using the expectation-maximization ( em ) algorithm . we evaluate the model on two different text data sets ( i.e. , a news article data set and a laptop review data set ) , and compare it with a baseline clustering method also based on a mixture model . experiment results show that the model is quite effective in discovering the latent common themes across collections and performs significantly better than our baseline mixture model .
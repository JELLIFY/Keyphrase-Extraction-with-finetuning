time and sample efficient discovery of markov blankets and direct causal relations data mining with bayesian network learning has two important characteristics : under conditions learned edges between variables correspond to casual influences , and second , for every variable t in the network a special subset ( markov blanket ) identifiable by the network is the minimal variable set required to predict t. however , all known algorithms learning a complete bn do not scale up beyond a few hundred variables . on the other hand , all known sound algorithms learning a local region of the network require an exponential number of training instances to the size of the learned region . the contribution of this paper is two-fold . we introduce a novel local algorithm that returns all variables with direct edges to and from a target variable t as well as a local algorithm that returns the markov blanket of t. both algorithms ( i ) are sound , ( ii ) can be run efficiently in datasets with thousands of variables , and ( iii ) significantly outperform in terms of approximating the true neighborhood previous state-of-the-art algorithms using only a fraction of the training size required by the existing methods . a fundamental difference between our approach and existing ones is that the required sample depends on the generating graph connectivity and not the size of the local region ; this yields up to exponential savings in sample relative to previously known algorithms . the results presented here are promising not only for discovery of local causal structure , and variable selection for classification , but also for the induction of complete bns .
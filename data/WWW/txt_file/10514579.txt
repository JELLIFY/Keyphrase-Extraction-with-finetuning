detecting wikipedia vandalism with active learning and statistical language models this paper proposes an active learning approach using language model statistics to detect wikipedia vandalism . wikipedia is a popular and influential collaborative information system . the collaborative nature of authoring , as well as the high visibility of its content , have exposed wikipedia articles to vandalism . vandalism is defined as malicious editing intended to compromise the integrity of the content of articles . extensive manual efforts are being made to combat vandalism and an automated approach to alleviate the laborious process is needed . this paper builds statistical language models , constructing distributions of words from the revision history of wikipedia articles . as vandalism often involves the use of unexpected words to draw attention , the fitness ( or lack thereof ) of a new edit when compared with language models built from previous versions may well indicate that an edit is a vandalism instance . in addition , the paper adopts an active learning model to solve the problem of noisy and incomplete labeling of wikipedia vandalism . the wikipedia domain with its revision histories offers a novel context in which to explore the potential of language models in characterizing author intention . as the experimental results presented in the paper demonstrate , these models hold promise for vandalism detection . 
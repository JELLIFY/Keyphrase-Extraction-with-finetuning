the cost of privacy : destruction of data-mining utility in anonymized data publishing re-identification is a major privacy threat to public datasets containing individual records . many privacy protection algorithms rely on generalization and suppression of `` quasi-identifier '' attributes such as zip code and birthdate . their objective is usually syntactic sanitization : for example , k-anonymity requires that each `` quasi-identifier '' tuple appear in at least k records , while l-diversity requires that the distribution of sensitive attributes for each quasi-identifier have high entropy . the utility of sanitized data is also measured syntactically , by the number of generalization steps applied or the number of records with the same quasi-identifier . in this paper , we ask whether generalization and suppression of quasi-identifiers offer any benefits over trivial sanitization which simply separates quasi-identifiers from sensitive attributes . previous work showed that k-anonymous databases can be useful for data mining , but k-anonymization does not guarantee any privacy . by contrast , we measure the tradeoff between privacy ( how much can the adversary learn from the sanitized records ? ) and utility , measured as accuracy of data-mining algorithms executed on the same sanitized records . for our experimental evaluation , we use the same datasets from the uci machine learning repository as were used in previous research on generalization and suppression . our results demonstrate that even modest privacy gains require almost complete destruction of the data-mining utility . in most cases , trivial sanitization provides equivalent utility and better privacy than k-anonymity , l-diversity , and similar methods based on generalization and suppression .
model compression often the best performing supervised learning models are ensembles of hundreds or thousands of base-level classifiers . unfortunately , the space required to store this many classifiers , and the time required to execute them at run-time , prohibits their use in applications where test sets are large ( e.g. google ) , where storage space is at a premium ( e.g. pdas ) , and where computational power is limited ( e.g. hea-ring aids ) . we present a method for `` compressing '' large , complex ensembles into smaller , faster models , usually without significant loss in performance .
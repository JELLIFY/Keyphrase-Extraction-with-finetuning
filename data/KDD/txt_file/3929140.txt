formulating distance functions via the kernel trick tasks of data mining and information retrieval depend on a good distance function for measuring similarity between data instances . the most effective distance function must be formulated in a context-dependent ( also application - , data - , and user-dependent ) way . in this paper , we propose to learn a distance function by capturing the nonlinear relationships among contextual information provided by the application , data , or user . we show that through a process called the `` kernel trick , '' such nonlinear relationships can be learned efficiently in a projected space . theoretically , we substantiate that our method is both sound and optimal . empirically , using several datasets and applications , we demonstrate that our method is effective and useful .
a general framework for accurate and fast regression by data summarization in random decision trees predicting the values of continuous variable as a function of several independent variables is one of the most important problems for data mining . a very large number of regression methods , both parametric and nonparametric , have been proposed in the past . however , since the list is quite extensive and many of these models make rather explicit , strong yet different assumptions about the type of applicable problems and involve a lot of parameters and options , choosing the appropriate regression methodology and then specifying the parameter values is a none-trivial , sometimes frustrating , task for data mining practitioners . choosing the inappropriate methodology can have rather disappointing results . this issue is against the general utility of data mining software . for example , linear regression methods are straightforward and well-understood . however , since the linear assumption is very strong , its performance is compromised for complicated non-linear problems . kernel-based methods perform quite well if the kernel functions are selected correctly . in this paper , we propose a straightforward approach based on summarizing the training data using an ensemble of random decisions trees . it requires very little knowledge from the user , yet is applicable to every type of regression problem that we are currently aware of . we have experimented on a wide range of problems including those that parametric methods performwell , a large selection of benchmark datasets for nonparametric regression , as well as highly non-linear stochastic problems . our results are either significantly better than or identical to many approaches that are known to perform well on these problems .